\section{EXPERIMENTS \& DISCUSSIONS}\label{sec:results}

The effectiveness of the proposed Approximate Spanning Tree (AST) and
the Prime Number based Heuristic (PNH) has been empirically assessed
using two different types of datasets.  The first dataset was
Expressed Sequence Tags (ESTs) from different species as summarized in
Table~\ref{tab:est-ds}.  This dataset consists of characteristic
short reads (about 300 -- 500 nucleotides) that have been used by
several investigators in the past.  

\input{est_dataset.tex}

\q{S8} is a synthetic data set from James \etal~\cite{james-18}.  The
\q{C08} is a synthetically generated test dataset generated using
ESTsim (see ~\cite{hazelhurst-11} for details).  The \q{A076941}
dataset contains a subset of \emph{Arabidopsis} \emph{Thaliana} ESTs
downloaded from Genbank.  The \q{C08} and \q{A076941} datasets were
primary used because they have been used by Hazelhurst
\etal~\cite{hazelhurst-11} for assessment of \q{wcd-kaboom}.


The second dataset was viral genome fragments summarized in
Table~\ref{tab:virus-ds}.  This datasets consists of \emph{much}
longer reads (1000s of nucleotides) when compared to the EST dataset.
The \q{HA} dataset consists of Haemagglutinin (HA) segments from
multiple Influenza serotypes (H1 -- H19) and should ideally result in
20 clusters.  This dataset has been downloaded from Influenza Research
Database~\cite{bogner-06}.  The \q{Dengue} dataset consists of the
full genome of all 4 serotypes of dengue.  These long genomes are
analogous to the long reads (\mytilde 10,000 bases) produced by the
RSII platform from Pacific bioscience.  It has been downloaded from
Virus Variation Resource~\cite{brister-14}, specifically from the
Virus Pathogen Database~\cite{pickett-12}.  Ideally, this dataset
should generate 4 clusters but due to high homology between the
serotypes, most clustering software yield just 1 cluster.

\input{virus_dataset.tex}

\subsection{Experimental Platform}

The experiments reported in this paper have been conducted on a
contemporary compute cluster running PBS.  Each compute node on the
cluster consists of two (dual socket) Intel
Xeon\textsuperscript{\textregistered}\/ CPUs (Gold 6126 @ 2.60 GHz)
with hyperthreading disabled.  Each CPU has 14 cores and 19 MiB of
shared L3 cache.  The cluster runs CentOS 7.5 (Linux kernel version
3.10.  All of the software compiled using GNU Compiler Collection
(GCC) version 6.3.0 at \q{-O2} optimization level.  The timings and
memory usage as been recorded using \q{/usr/bin/time} utility.

\subsection{Design of Experiments}

Prior to conducting experiments, the reads in each of the datasets
were randomly shuffled to eliminate any potential patterns that may be
inherently present when the datasets were downloaded.  Each tool
configuration was run as an independent PBS job with 1 core and 12 GB
of memory reserved for it.  The experimental observations for the EST
data and Virus data are shown in Table~\ref{tab:est} and
Table~\ref{tab:virus}.  In these two tables, the row \q{wcd-kbm}
corresponds to \q{wcd} with \q{kaboom} filter configuration.  The run
time data for \q{wcd-kaboom} includes the time taken to generate
suffix arrays as discussed by Hazelhurst \etal~\cite{hazelhurst-11}.
The row with name \q{MST} shows results for base case \peace\/ run
using its default MST.  The rows labeled \q{AST=1} and \q{AST=0.8}
show results for AST with AST-thresholds set to 1.0 and 0.8
respectively.  The rows with \q{PNH} prefix show results from using
the heuristic along with the default $u/v$ and $t/v$ heuristics in
\peace.

\subsection{Discussions}

The results from various experiments conducted using the EST datasets
from Table~\ref{tab:est-ds} are summarized in Table~\ref{tab:est}.
Similarly, the results for the virus datasets from
Table~\ref{tab:virus-ds} are summarized in Table~\ref{tab:virus}.  The
NMI and purity values have been computed using the clustering
generated by \peace-MST as the reference as discussed in
Section~\ref{sec:metrics}.

For the EST datasets, \q{wcd-kaboom} consistently outperformed
\peace-MST as reported by Hazelhurst \etal~\cite{hazelhurst-11}.
However, as shown by the results, the proposed AST approach was
considerably faster than \peace-MST without much compromise in the
quality in most of the cases.  However, \q{wcd-kaboom} outperformed
the AST approach for two out of the three datasets.  In these
datasets, the performance gains of the AST approach was muted due to
the large number of small clusters -- \ie\/ only a few reads were
similar and hence reads could not be rapidly added to the AST (see
discussion in Section~\ref{sec:ast}).  In other words, Kaboom filter
was more successful at eliminating redundant calls to heuristics and
the heavyweight d2-score generation when compared to AST.  In the case
of the \q{A076941} dataset, a dominant portion of the runtime was
consumed for running the $u/v$ and $t/v$ heuristics.  Analysis of the
runtime behaviors suggests that a threshold based on number of
successful reads would be beneficial here -- \ie\/ once some $s$ reads
below the AST-threshold have been found, stop checking further reads.
We plan to pursue this optimization in the near future to assess its
efficacy.  Some degradation was observed in the \q{C08} case, with the
AST approach generating more clusters.  This results in some
degradation of NMI with respect to \peace-MST, but the NMI of 0.837 is
comparable to \q{wcd}'s 0.847.


\input{results_table_est.tex}

The most conspicuous performance improvement was observed in the HA
dataset, where the AST method finished clustering in \mytilde 16
seconds, while \q{wcd-kaboom} and \peace-MST took 149 mins and 930
mins respectively.  This corresponds to a remarkable \textgreater\/
550\texttimes\/ and \textgreater\/ 3400\texttimes\/ performance
improvements!  In the case of the Dengue dataset, the performance
improvement of AST over \q{wcd-kaboom} was \mytilde 90\texttimes.  The
results suggest that the AST method will yield good performance
improvements for datasets with large clusters.

\textbf{An unforeseen benefit}: Our experiments revealed an
interesting unforeseen benefit of the AST method for the HA dataset.
The dataset has 19 different serotypes and a few unclassified
reads. However, the serotypes are highly homologous and hence, the
more accurate MST-based approach results in just 8 clusters.  However,
with the AST approach results in detection of these serotypes as shown
in Table~\ref{tab:virus}.  For example, with a threshold of 0.95, the
AST method generates 20 clusters separating out the serotypes which
could be a desirable result.  This behavior will require further
investigation.

\input{results_table_virus.tex}

The Prime Numbers based Heuristic (PNH) was able to further boost
runtime performance in the \q{HA} dataset, but at the cost of
reduction in NMI.  For this dataset prime heuristics was able to
provide another 18\% improvement (see Table~\ref{tab:virus}.  It also
increased performance in the \q{Dengue} dataset by another 50\% with
NMI comparable to AST.  For the datasets having relatively shorter
sequences and a large number of clusters (\ie\/ \q{S8}, \q{C08}, and
\q{A076941}) the PNH was slower.  This is attributed to the additional
computational overhead of the PNH and this overhead is not effectively
amortized. Overall, prime heuristics provided clustering with lower
NMIs, except in the case of \q{S8} dataset.  These results suggested
that the PNH is effective in clustering viral genomic data possessing
highly similar, large nucleotide sequences. This type of clustering
has a several biological applications including analysis of microbial
genome variations, Influenza A subtype identification, and identifying
novel viral strains.

\subsection{Memory consumption}

A drawback inherited from \peace\/ is the increased memory usage for
clustering.  For example, in the case of the \q{C08} dataset, the
default MST-based clustering in \peace\/ consumes over 12 GB of RAM
while the AST approach consumes about 5 GB.  In contrast,
\q{wcd-kaboom} consumes only 26 MB (even when the raw dataset size if
48 MB).  The low memory footprint of \q{wcd-kaboom} is attributed to
the fact that it only maintains the suffix array in memory while
processing 1 read at a time.

The increased memory footprint of \peace\/ arises from 2 factors.
First, \peace\/ experiments were conducted by holding all the reads in
memory.  It does have an option to load reads on-demand, but this
option has not been used to minimize runtime.  The largest fraction of
memory usage arises from the caches maintained by \peace.  The cache
has been implemented using a standard binary heap.  It serves as a
priority queue to identify the next read to be added to the MST/AST.
This cache is pruned, but not aggressively, to reduce runtime.
Performing a periodic, deep pruning of this cache will reduce memory
footprint, but at the cost of some increase in runtime.  In addition,
alternative data structures such as 3-tier heap~\cite{higiro-17} can
be utilized to enable efficient pruning.  We are planning to explore
such enhancements to \peace\/ in the near future.
